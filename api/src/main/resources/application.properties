#logging Properties
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=${HIBERNATE_SQL_PARAM_LOG_LEVEL}
logging.level.org.springframework.security=${SPRING_SECURITY_LOG_LEVEL}
logging.level.org.springframework.web=${SPRING_WEB_LOG_LEVEL}
logging.level.ca.bc.gov.educ.penreg=${APP_LOG_LEVEL}
logging.level.org.springframework.boot.autoconfigure.logging=${SPRING_BOOT_AUTOCONFIG_LOG_LEVEL}
spring.mvc.log-request-details=${SPRING_SHOW_REQUEST_DETAILS}

#DB Properties
spring.datasource.url=${JDBC_URL}
spring.datasource.username=${ORACLE_USERNAME}
spring.datasource.password=${ORACLE_PASSWORD}
spring.jpa.database-platform=org.hibernate.dialect.OracleDialect
spring.jpa.hibernate.ddl-auto=none

spring.jackson.deserialization.fail-on-unknown-properties=false
spring.security.oauth2.resourceserver.jwt.issuer-uri=${TOKEN_ISSUER_URL}
spring.security.oauth2.resourceserver.jwt.jwk-set-uri=${TOKEN_ISSUER_URL}/protocol/openid-connect/certs
management.endpoint.metrics.enabled=true
management.endpoints.web.exposure.include=*
management.endpoint.prometheus.enabled=true
management.prometheus.metrics.export.enabled=true
spring.jpa.properties.hibernate.generate_statistics=false
spring.datasource.hikari.max-lifetime=120000
spring.jmx.enabled=false
spring.flyway.baseline-on-migrate=true
spring.flyway.table=FLYWAY_SCHEMA_HISTORY
spring.flyway.baseline-version=0
spring.flyway.enabled=true
logging.file.name=/logs/app.log
logging.logback.rollingpolicy.max-file-size=5MB
logging.logback.rollingpolicy.clean-history-on-start=true
logging.logback.rollingpolicy.max-history=1
logging.pattern.file={"time_stamp":"%d{yyyy-MM-dd HH:mm:ss.SSS}","level":"%3p" ,"thread":"%t" ,"class":"%logger{36}","msg":"%replace(%msg){'[\n\r\"]',''}", "exception":"%replace(%rEx{10}){'[\n\r\"]',''}","http_event":%X{httpEvent:-""},"message_event":%X{messageEvent:-""}, "saga_retry":%X{sagaRetry:-""}}%nopex%n
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss.SSS} | [%5p] | [%t] | [%logger{36}] | [%replace(%msg){'[\n\r\"]',''} %X{httpEvent} %X{messageEvent}] | %replace(%rEx{10}){'[\n\r\"]',''}%nopex%n
# <p>Example patterns:
# <ul>
# <li>"0 0 * * * *" = the top of every hour of every day.</li>
# <li>"*&#47;10 * * * * *" = every ten seconds.</li>
# <li>"0 0 8-10 * * *" = 8, 9 and 10 o'clock of every day.</li>
# <li>"0 0 6,19 * * *" = 6:00 AM and 7:00 PM every day.</li>
# <li>"0 0/30 8-10 * * *" = 8:00, 8:30, 9:00, 9:30, 10:00 and 10:30 every day.</li>
# <li>"0 0 9-17 * * MON-FRI" = on the hour nine-to-five weekdays</li>
# <li>"0 0 0 25 12 ?" = every Christmas Day at midnight</li>
#	 */
scheduled.jobs.extract.unprocessed.pen.web.blobs.cron=${SCHEDULED_JOBS_EXTRACT_UNPROCESSED_PEN_WEB_BLOBS_CRON}
scheduled.jobs.extract.unprocessed.penwebfiles.pen.web.blobs.cron=${SCHEDULED_JOBS_EXTRACT_UNPROCESSED_PENWEB_PEN_WEB_BLOBS_CRON}

#Need to make sure that this value is set properly based on the above value of cron expression.
#EX: If the cron is set to run every 10 minutes, make sure this is set to 9 minutes
scheduled.jobs.extract.unprocessed.pen.web.blobs.cron.lockAtLeastFor=${SCHEDULED_JOBS_EXTRACT_UNPROCESSED_PEN_WEB_BLOBS_CRON_LOCK_AT_LEAST_FOR}

#Need to make sure that this value is set properly based on the above value of cron expression.
#EX: If the cron is set to run every 10 minutes, make sure this is set to 9 minutes 55 Seconds.
scheduled.jobs.extract.unprocessed.pen.web.blobs.cron.lockAtMostFor=${SCHEDULED_JOBS_EXTRACT_UNPROCESSED_PEN_WEB_BLOBS_CRON_LOCK_AT_MOST_FOR}

#This is required to map long raw, please see below links, even if hibernate documentation mentions {hibernate.dialect.oracle.prefer_longvarbinary}
# this as the property name, it is not correct.
#https://hibernate.atlassian.net/browse/HHH-10345
#https://in.relation.to/2016/02/17/hibernate-orm-508-final-release/
spring.jpa.properties.hibernate.dialect.oracle.prefer_long_raw=true
#Print the queries
spring.jpa.show-sql=${SPRING_JPA_SHOW_SQL}
##Be careful when changing below values in config map....
scheduled.jobs.extract.uncompleted.sagas.cron=${SCHEDULED_JOBS_EXTRACT_UNCOMPLETED_SAGAS_CRON}
scheduled.jobs.extract.uncompleted.sagas.cron.lockAtLeastFor=${SCHEDULED_JOBS_EXTRACT_UNCOMPLETED_SAGAS_CRON_LOCK_AT_LEAST_FOR}
scheduled.jobs.extract.uncompleted.sagas.cron.lockAtMostFor=${SCHEDULED_JOBS_EXTRACT_UNCOMPLETED_SAGAS_CRON_LOCK_AT_MOST_FOR}
scheduled.jobs.extract.unprocessed.students.cron=${SCHEDULED_JOBS_EXTRACT_UNPROCESSED_STUDENTS_CRON}
scheduled.jobs.extract.unprocessed.students.cron.lockAtLeastFor=${SCHEDULED_JOBS_EXTRACT_UNPROCESSED_STUDENTS_CRON_LOCK_AT_LEAST_FOR}
scheduled.jobs.extract.unprocessed.students.cron.lockAtMostFor=${SCHEDULED_JOBS_EXTRACT_UNPROCESSED_STUDENTS_CRON_LOCK_AT_MOST_FOR}
scheduled.jobs.mark.processed.batches.active.cron=${SCHEDULED_JOBS_MARK_PROCESSED_BATCHES_ACTIVE_CRON}
scheduled.jobs.mark.processed.batches.active.cron.lockAtLeastFor=${SCHEDULED_JOBS_MARK_PROCESSED_BATCHES_ACTIVE_CRON_LOCK_AT_LEAST_FOR}
scheduled.jobs.mark.processed.batches.active.cron.lockAtMostFor=${SCHEDULED_JOBS_MARK_PROCESSED_BATCHES_ACTIVE_LOCK_AT_MOST_FOR}
scheduled.jobs.process.loaded.batches.for.repeats.cron=${SCHEDULED_JOBS_PROCESS_LOADED.BATCHES_FOR_REPEATS_CRON}
scheduled.jobs.process.loaded.batches.for.repeats.cron.lockAtLeastFor=${SCHEDULED_JOBS_PROCESS_LOADED_BATCHES_FOR_REPEATS_CRON_LOCK_AT_LEAST_FOR}
scheduled.jobs.process.loaded.batches.for.repeats.cron.lockAtMostFor=${SCHEDULED_JOBS_PROCESS_LOADED_BATCHES_FOR_REPEATS_CRON_LOCK_AT_MOST_FOR}
scheduled.jobs.purge.soft.deleted.batch.records.cron=${SCHEDULED_JOBS_PURGE_SOFT_DELETED_RECORDS_CRON}
scheduled.jobs.purge.old.saga.records.cron=${SCHEDULED_JOBS_PURGE_OLD_SAGA_RECORDS_CRON}
schedule.jobs.load.pen.coordinators.cron=0 0 0/4 * * *
spring.jpa.open-in-view=false
#This is used to run redis in local without cluster mode, in application-local.properties change this to local
#Add Redis cluster node address. Use follow format -- <code>host:port</code>. since it is a service in OS, we just give one entry.
#Client details to get token to make api calls.
client.id=${CLIENT_ID}
client.secret=${CLIENT_SECRET}
url.token=${TOKEN_URL}
#Below are for making API calls to Student after getting the token.
url.api.student=${STUDENT_API_URL}
url.api.pen.services=${PEN_SERVICES_API_URL}
url.api.school=${SCHOOL_API_URL}
#How many days after processing a batch request is considered a repeat
repeat.time.window.psi=${REPEAT_TIME_WINDOW_PSI}
repeat.time.window.k12=${REPEAT_TIME_WINDOW_K12}
spring.datasource.hikari.maximum-pool-size=${SPRING_DATASOURCE_HIKARI_MAXIMUM_POOL_SIZE}
spring.datasource.hikari.minimum-idle=${SPRING_DATASOURCE_HIKARI_MINIMUM_IDLE}
nats.server=${NATS_URL}
nats.maxReconnect=${NATS_MAX_RECONNECT}
nats.connectionName=PEN-REG-BATCH-API
purge.records.saga.after.days=${PURGE_RECORDS_SAGA_AFTER_DAYS}
soft.deleted.batch.records.retention.days=${SOFT_DELETED_RETENTION_DAYS}
#Number of records in batch before it's held back
number.records.for.batch.hold=${HOLD_BATCHES_EQUAL_OR_LARGER_THAN}
# from email when the batch file could not be processed due to formatting errors.
pen.coordinator.email=${PEN_COORDINATOR_EMAIL}
pen.coordinator.mailing.address=${PEN_COORDINATOR_MAILING_ADDRESS}
pen.coordinator.telephone=${PEN_COORDINATOR_TELEPHONE}
pen.coordinator.facsimile=${PEN_COORDINATOR_FACSIMILE}
spring.data.redis.client-name=PEN-REG-BATCH-API
spring.data.redis.repositories.enabled=false
spring.data.redis.client-type=lettuce
initialization.background.enabled=true
#The below needs to be a comma separated list.
schedule.jobs.load.school.cron=0 0 0/12 * * *
student.threshold.generate.pdf=${STUDENT_THRESHOLD_GENERATE_PDF}

threads.min.subscriber=${THREADS_MIN_SUBSCRIBER}
threads.max.subscriber=${THREADS_MAX_SUBSCRIBER}
sagas.max.pending=${SAGAS_MAX_PENDING}
sagas.max.parallel=${SAGAS_MAX_PARALLEL}

#Logging to debug Hikari
logging.level.com.zaxxer.hikari.HikariConfig=DEBUG
logging.level.com.zaxxer.hikari=TRACE
spring.datasource.hikari.leak-detection-threshold=10000
spring.jpa.properties.hibernate.connection.handling_mode=DELAYED_ACQUISITION_AND_RELEASE_AFTER_TRANSACTION